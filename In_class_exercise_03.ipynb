{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeerrajuP/VeerrajuP/blob/main/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaUT34VXdTHH"
      },
      "source": [
        "## The third In-class-exercise (9/29/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehqmgHbIdTHI"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfDFSytrdTHI"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "bI2k03qSdTHJ",
        "outputId": "65b74af4-c150-46f9-97b7-f0410f04c6e9"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The basic purpose of sentiment analysis from twitter data is to detect whether prople's tweets have positive or negatives feelings.\n",
        "\n",
        "In this work, both text classifications and text mining will be employed, with the text mining process bringing in data from twitter and text classification classifying the incoming data into smaller sections such as sentences, words, characters, punctuation and so on.\n",
        "\n",
        "The features to be extracted in this task are Uppercase words count, Numeric count, Special characters count, Stop words, Characters count, Word count, Sentence count.\n",
        "\n",
        "we can compare data for positive and negative attitudes. Finally we can determine if the overall sentiment of the tweets is favourable or negative by adding up all of the sentiment counts\n",
        "\n",
        "We can see the sentiments of people on twitter utilizing text mining and text classification in this way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nPlease write you answer here:\\n\\nThe basic purpose of sentiment analysis from twitter data is to detect whether prople's tweets have positive or negatives feelings.\\n\\nIn this work, both text classifications and text mining will be employed, with the text mining process bringing in data from twitter and text classification classifying the incoming data into smaller sections such as sentences, words, characters, punctuation and so on.\\n\\nThe features to be extracted in this task are Uppercase words count, Numeric count, Special characters count, Stop words, Characters count, Word count, Sentence count.\\n\\nwe can compare data for positive and negative attitudes. Finally we can determine if the overall sentiment of the tweets is favourable or negative by adding up all of the sentiment counts\\n\\nWe can see the sentiments of people on twitter utilizing text mining and text classification in this way.\\n\\n\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBNvKe3KdTHJ"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "RhccyuLRdTHK",
        "outputId": "722a7cf5-69a2-459d-c74f-fd849f472d06"
      },
      "source": [
        "#program to extract these features you discussed above. These are the few samples text data for the feature\n",
        "\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "\n",
        "con_key = \"Sl9QlYe2uIYFB4c56ht3suQpx\"\n",
        "con_secret = \"itmSoGGJBHAjnhcy0jZOyBHEEB9oYztj5mLBAa7yJm4tRAb2ai\"\n",
        "access_token = \"1438705493510344707-C3jtWFSrEjfyj0dtBY09lXUVsDL0oi\"\n",
        "access_token_secret = \"XEnNE1Mn6WupA0XnSV8aVNYXrV1k9no4iq6BMDZEOAV5d\"\n",
        "auth = tweepy.OAuthHandler(con_key, con_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "text_query = 'ACLU'\n",
        "max_tweets = 200\n",
        "tweets = tweepy.Cursor(api.search,q=text_query,lang='en', location = 'New york', since = '2021-02-01', until = '2021-09-29').items(max_tweets)\n",
        "tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.user.name, tweet.user.screen_name, tweet.user.id_str, tweet.user.location, tweet.user.url, tweet.user.description, tweet.user.verified, tweet.user.followers_count, tweet.user.friends_count, tweet.user.favourites_count, tweet.user.statuses_count, tweet.user.listed_count, tweet.user.created_at, tweet.user.profile_image_url_https, tweet.user.default_profile, tweet.user.default_profile_image] for tweet in tweets]\n",
        "tweets_df = pd.DataFrame(tweets_list)\n",
        "tweets_df\n",
        "Tweets = pd.DataFrame()\n",
        "Tweets['Tweets'] = tweets_df[0]\n",
        "Tweets\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import *\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "Tweet1 = pd.DataFrame()\n",
        "Tweet1['Tweets'] = tweets_df[0]\n",
        "Tweet = Tweets\n",
        "Tweet1['Tweets'] = Tweet1['Tweets'].apply(sent_tokenize)\n",
        "Tweet['Sen_Count'] = Tweet1['Tweets'].apply(len)\n",
        "Tweet['Wd_Count'] = Tweet['Tweets'].apply(lambda x: len(str(x).split(\" \")))\n",
        "Tweet['Char_Count'] = Tweet['Tweets'].str.len()\n",
        "\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  return (sum(len(word) for word in words)/len(words))\n",
        "\n",
        "Tweet['Avg_Word'] = Tweet['Tweets'].apply(lambda x: avg_word(x))\n",
        "stop = stopwords.words('english')\n",
        "Tweet['Stopwords'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
        "Special_Characters = '[@_!#$%^&*()<>?/\\|}{~:]'\n",
        "SC_Tuple = tuple(Special_Characters)\n",
        "Tweet['Special_Characters_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.startswith(SC_Tuple)]))\n",
        "Tweet['Numerics_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "Tweet['Upper_Count'] = Tweet['Tweets'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "Tweet\n",
        "\n",
        "import nltk\n",
        "nltk.download('wdnet')\n",
        "\n",
        "Tweet2 = pd.DataFrame()\n",
        "Tweet2['Tweets'] = Tweet['Tweets'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].str.replace('[^\\w\\s]','')\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "common = pd.Series(' '.join(Tweet2['Tweets']).split()).value_counts()[:10]\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in common))\n",
        "rare = pd.Series(' '.join(Tweet2['Tweets']).split()).value_counts()[-10:]\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare))\n",
        "\n",
        "from textblob import TextBlob\n",
        "Tweet2['Tweets'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
        "\n",
        "TextBlob(Tweet2['Tweets'][1]).words\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "Tweet2['Tweets'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "from textblob import Word\n",
        "Tweet2['Tweets'] = Tweet2['Tweets'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "Tweet2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading wdnet: Package 'wdnet' not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>newliberalspod century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>braincures govacctproj awhistleblowing whistle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow politics make strange bedfellow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>nypost apologizes changing rbg quote delete wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>peace4all17 kdansky like terf thing bc used cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>kgotsch congratulation many focused determined...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>need pathway citizenship immigrant call americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>jimbuwdawg kdansky start gender identity ideol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets\n",
              "0                               newliberalspod century\n",
              "1    patrick_madden call federal prosecutor investi...\n",
              "2    braincures govacctproj awhistleblowing whistle...\n",
              "3                  wow politics make strange bedfellow\n",
              "4    patrick_madden call federal prosecutor investi...\n",
              "..                                                 ...\n",
              "195  nypost apologizes changing rbg quote delete wo...\n",
              "196  peace4all17 kdansky like terf thing bc used cl...\n",
              "197  kgotsch congratulation many focused determined...\n",
              "198  need pathway citizenship immigrant call americ...\n",
              "199  jimbuwdawg kdansky start gender identity ideol...\n",
              "\n",
              "[200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-KO89ZdTHK"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HPZBqsMZdTHK",
        "outputId": "00e5cbf0-75ff-4ec4-9759-a230d9f15223"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "def sentiment_calc(text):\n",
        "    try:\n",
        "        return TextBlob(text).sentiment\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "#We added the outcome to data\n",
        "Tweet2['Polarity_Subjectivity'] = Tweet2['Tweets'].apply(sentiment_calc)\n",
        "Tweet2['Polarity'] = Tweet2['Polarity_Subjectivity'].apply(lambda x: x[0])\n",
        "\n",
        "def sentiment(Polarity):\n",
        "  if Polarity>0:\n",
        "    return '+ve'\n",
        "  else:\n",
        "    return '-ve'\n",
        "#polarity is negative sentiment is filtered as negative and viceversa\n",
        "\n",
        "Tweet2['Sentiment'] = Tweet2['Polarity'].apply(sentiment)\n",
        "Tweet2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Polarity_Subjectivity</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>newliberalspod century</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>braincures govacctproj awhistleblowing whistle...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow politics make strange bedfellow</td>\n",
              "      <td>(0.025, 0.575)</td>\n",
              "      <td>0.025</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patrick_madden call federal prosecutor investi...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>nypost apologizes changing rbg quote delete wo...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>peace4all17 kdansky like terf thing bc used cl...</td>\n",
              "      <td>(0.10000000000000002, 0.3833333333333333)</td>\n",
              "      <td>0.100</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>kgotsch congratulation many focused determined...</td>\n",
              "      <td>(0.5, 0.5)</td>\n",
              "      <td>0.500</td>\n",
              "      <td>+ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>need pathway citizenship immigrant call americ...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>jimbuwdawg kdansky start gender identity ideol...</td>\n",
              "      <td>(0.0, 0.0)</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-ve</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tweets  ... Sentiment\n",
              "0                               newliberalspod century  ...       -ve\n",
              "1    patrick_madden call federal prosecutor investi...  ...       -ve\n",
              "2    braincures govacctproj awhistleblowing whistle...  ...       -ve\n",
              "3                  wow politics make strange bedfellow  ...       +ve\n",
              "4    patrick_madden call federal prosecutor investi...  ...       -ve\n",
              "..                                                 ...  ...       ...\n",
              "195  nypost apologizes changing rbg quote delete wo...  ...       -ve\n",
              "196  peace4all17 kdansky like terf thing bc used cl...  ...       +ve\n",
              "197  kgotsch congratulation many focused determined...  ...       +ve\n",
              "198  need pathway citizenship immigrant call americ...  ...       -ve\n",
              "199  jimbuwdawg kdansky start gender identity ideol...  ...       -ve\n",
              "\n",
              "[200 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}